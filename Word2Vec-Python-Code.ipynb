{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09b04e-93c1-4dd0-8865-4a8b2904f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "nome_file = \"./DATI/Dataset.csv\"\n",
    "dati = pandas.read_csv(nome_file, encoding=\"utf-8\", sep=\",\")\n",
    "dati.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "88c93477-a5ce-43d4-824e-ce3e7d7495db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessa_testo (testo) -> str:\n",
    "\n",
    "    # RIMUOVERE I LINK E GLI AT\n",
    "    testo = re.sub(r\"http\\S+\", \"\", testo) \n",
    "    testo = re.sub(\"@\\S+\", \"\", testo)\n",
    "    testo = re.sub(\"[^A-Za-z\\à\\è\\é\\ì\\ò\\ù]+\", \" \", testo)\n",
    "    \n",
    "    parole_token = nltk.word_tokenize(testo)\n",
    "    parole_token = [n.lower().strip() for n in parole_token]\n",
    "    parole_token = [w for w in parole_token if not w in stopwords.words(\"italian\")]\n",
    "\n",
    "    return parole_token\n",
    "\n",
    "dati[\"testi_puliti\"] = dati.text.apply(lambda x: preprocessa_testo(x))\n",
    "\n",
    "frasi = list(dati[\"testi_puliti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb6785-4b61-400c-bb7e-477ecec30105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Inizializzaimo il Word2Vec\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "modello = Word2Vec(vector_size=100,  # Dimensione degli embedding (100-200 per dataset piccoli/medi)\n",
    "                   window=5,         # Contesto di 5 parole (ideale per commenti brevi)\n",
    "                   min_count=5,      # Ignora parole con <5 occorrenze (riduce rumore)\n",
    "                   sg=0,             # Modalità CBOW (più veloce e funziona bene con poco testo)\n",
    "                   hs=0,             # Disabilita Hierarchical Softmax (usa Negative Sampling)\n",
    "                   negative=10,      # Campiona 10 parole negative (bilancio qualità-velocità)\n",
    "                   epochs=30,        # Più epoche per dataset piccoli (default=5)\n",
    "                   workers=4,        # Threads per training parallelo\n",
    "                   alpha=0.025,      # Learning rate iniziale\n",
    "                   min_alpha=0.0001, # Learning rate finale (decresce linearmente)\n",
    "                   cbow_mean=1       # Media dei vettori di contesto (default)\n",
    "                   )\n",
    "\n",
    "# Costruiamo il vocabolario\n",
    "modello.build_vocab(frasi)\n",
    "\n",
    "# Addestriamo il modello\n",
    "modello.train(frasi,\n",
    "              total_examples=modello.corpus_count,\n",
    "              epochs=1000)\n",
    "\n",
    "# Salviamo e ricarichiamo il nuovo modello + costruzione vocabolario\n",
    "modello.save(\"nuovoword2vec01.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d13d36-8522-48d8-b129-a2814a5a2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuovo_modello = Word2Vec.load(\"nuovoword2vec01.model\")\n",
    "parole = list(nuovo_modello.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4177d7c-3313-4dca-ac8d-c40f775a033f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Interrogazione del modello\n",
    "# vettore = nuovo_modello.wv[\"parola\"]\n",
    "# print(vettore)\n",
    "correlati = nuovo_modello.wv.most_similar(\"uomo\", topn = 25)\n",
    "print(*correlati, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c57be-f196-4a90-913d-9838259a1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = nuovo_modello.wv  # wv contiene i KeyedVectors\n",
    "similarity = word_vectors.similarity('maschio', 'criminale')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf37c92-1ea9-42c9-af05-9c8095ef9d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Carica il mio modello\n",
    "model = Word2Vec.load(\"nuovoword2vec01.model\")  \n",
    "# Lista keyword\n",
    "parole = ['maschio', 'maschile', 'femminile', 'patriarcato',\n",
    "          'violenza', 'criminale', 'femminicidio',  'italiani', 'immigrato', 'destra', 'sinistra']\n",
    "\n",
    "translation = ['Male', 'Masculine', 'Feminine', 'Patriarchy',\n",
    "          'Violence', 'Criminal', 'Femicide',  'Italians', 'Immigrant', 'Right-wing', 'Left-wing'] \n",
    "\n",
    "# Crea un array vuoto NxN\n",
    "matrice_similarita = np.zeros(\n",
    "    (len(parole), len(parole))\n",
    ")\n",
    "# Calcolo matrice di similarità effettiva\n",
    "# Uso enumerate per avere simultaneamente sia gli indici sia le parole\n",
    "for i, word1 in enumerate(parole):\n",
    "    for j, word2 in enumerate(parole):\n",
    "        matrice_similarita[i][j] = model.wv.similarity(word1, word2)\n",
    "        if matrice_similarita[i][j] > 0.99:\n",
    "            matrice_similarita[i][j] = 0\n",
    "          \n",
    "# Stabilisco una soglia per visualizzare i valori in matrice\n",
    "soglia = 0.11\n",
    "# Crea una maschera booleana per i valori sotto soglia\n",
    "mask_sotto_soglia = matrice_similarita <= soglia\n",
    "\n",
    "# Preparazione delle annotazioni sulla griglia\n",
    "# np.where trova gli indici degli elementi maggiori di soglia\n",
    "# Se un valore è maggiore di soglia, viene arrotondato a due decimali\n",
    "# Se un valore è minore o uguale a soglia, viene sostituito con \"\"\n",
    "annotations = np.where(\n",
    "    matrice_similarita > soglia,\n",
    "    np.round(matrice_similarita, 2),  # Mostra 2 decimali\n",
    "    \"\"                                # Stringa per valori sotto soglia\n",
    ")\n",
    "\n",
    "# Crea una nuova figura per un grafico con una dimensione specifica in pollici\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Importiamo lo stile Seaborn\n",
    "# font_scale=1.0, mantiene la dimensione standard.\n",
    "# font_scale=1.5, aumenta i font del 50%\n",
    "sns.set(font_scale=0.9)\n",
    "\n",
    "# Creazione heatmap come oggetto Axes di Matplotlib\n",
    "# Il nome ax è convenzionale\n",
    "ax = sns.heatmap(\n",
    "    matrice_similarita,\n",
    "    mask=mask_sotto_soglia,  # col parametro mask nascondiamo alcune celle\n",
    "                             # che abbiamo memorizzato nella maschera booleana\n",
    "    annot=annotations,       # annotazioni sono i valori della matrice filtrati\n",
    "    fmt=\"\",                  # annotazioni come sono fornite in annot,\n",
    "                             # senza formattazione.\n",
    "    cmap=\"Reds\",             # modello colore\n",
    "    # vmin=soglia,\n",
    "    # vmax=1,\n",
    "    xticklabels=translation,\n",
    "    yticklabels=translation,\n",
    "    linewidths=1,\n",
    "    cbar_kws={'label': 'Word2Vec Similarity'} # Etichetta colorbar\n",
    ")\n",
    "\n",
    "# Personalizzazione grafico\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "plt.tight_layout() # Regola automaticamente gli spazi tra gli elementi del grafico\n",
    "plt.show()         # Mostra il grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa22864-cecf-43e3-b8f2-5de0a9a4dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDURRE I DATI DI UN MODELLO W2V\n",
    "\n",
    "# Importiamo le istruzioni per la riduzione dei dati: t-SNE \n",
    "from sklearn.manifold import TSNE\n",
    "# Importiamo una libreria per la gestione degli array\n",
    "import numpy as np\n",
    "\n",
    "# Creiamo una funzione che riduce le dimensioni del modello\n",
    "def riduci_dimensioni(nuovo_modello):\n",
    "    \n",
    "    numero_dimensioni = 2\n",
    "\n",
    "    vettori = []        # Lista vuota di vettori\n",
    "    etichette = []      # Lista vuota di parole\n",
    "    \n",
    "    for parola in nuovo_modello.wv.index_to_key:\n",
    "        vettori.append(nuovo_modello.wv[parola])\n",
    "        etichette.append(parola)\n",
    "\n",
    "    # Un array è una lista che può contenere solo un tipo di elementi \n",
    "    # Gli array possono essere scritti in memoria in modo efficiente\n",
    "    # .asarray trasforma le liste in array\n",
    "    vettori = np.asarray(vettori)\n",
    "    etichette = np.asarray(etichette)\n",
    "\n",
    "    # t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "    # random_state corrisponde al seed (None = random)\n",
    "    # .fit_transform genera le nuove coordinate dei fattori\n",
    "    modello_tsne = TSNE(n_components=numero_dimensioni, random_state=2)\n",
    "    vettori = modello_tsne.fit_transform(vettori)\n",
    "\n",
    "    # Vettori e una lista di liste da due valori\n",
    "    # Ritagliamo per x il 1° e per y il 2° valore \n",
    "    x_vals = [v[0] for v in vettori]\n",
    "    y_vals = [v[1] for v in vettori]\n",
    "\n",
    "    return x_vals, y_vals, etichette\n",
    "\n",
    "x_vals, y_vals, etichette = riduci_dimensioni(nuovo_modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5a9a7c8-b947-4abc-a6c0-04daee867d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAPPRESENTAZIONE GRAFICA DI UN EMBEDDED MODEL\n",
    "\n",
    "def disegna_modello(x_vals, y_vals, etichette):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    # 'serif' (es. Times New Roman, Georgia)\n",
    "    # 'sans-serif' (es. Arial, Helvetica, Verdana)\n",
    "    # 'monospace' (es. Courier New, Consolas)\n",
    "    # 'cursive' (es. Comic Sans MS)\n",
    "    plt.rcParams['font.family'] = 'serif'  # Imposta il font globale\n",
    "    plt.rcParams['font.serif'] = ['Georgia']\n",
    "    \n",
    "    random.seed(12345)\n",
    "    global AVx\n",
    "    global AVy\n",
    "    AVx = []\n",
    "    AVy = []\n",
    "\n",
    "    # Inizializza il grafico\n",
    "    plt.figure(figsize=(10,10))\n",
    "    %matplotlib qt\n",
    "    \n",
    "    # Sceglie il tipo di grafico\n",
    "    plt.scatter(x_vals, y_vals, s=10, alpha=0.3)\n",
    "\n",
    "    for etica in range(len(etichette)):\n",
    "        if abs(x_vals[etica]) > 2 or abs(y_vals[etica]) > 2:\n",
    "        # I file Excel degli assi si riempiono se metti soglie basse\n",
    "            plt.annotate(etichette[etica], \n",
    "            (x_vals[etica], y_vals[etica]),\n",
    "            color=\"black\", fontsize=13)\n",
    "\n",
    "            duox = [x_vals[etica], etichette[etica]]\n",
    "            duoy = [y_vals[etica], etichette[etica]]\n",
    "\n",
    "            AVx.append(duox)\n",
    "            AVy.append(duoy)\n",
    "\n",
    "    # parole_da_cercare\n",
    "    parole_chiave = [\"uomo\", \"maschio\", \"donna\", \"criminale\", \"italiani\", \"femminile\",\n",
    "                     \"patriarcato\", \"destra\", \"sinistra\", \"stalker\", \"vittima\",\n",
    "                     \"immigrati\", \"violenza\", \"ragazzo\", \"giornalismo\", \"diritti\",\n",
    "                     \"maschile\", \"femminicidio\", \"ideologia\", \"politica\", \"stranieri\", \"giulia\"]\n",
    "\n",
    "    parole_chiave_sub = [\"man\", \"male\", \"woman\", \"criminal\", \"italians\", \"feminine\",\n",
    "                     \"patriarchy\", \"right-wing\", \"left-wing\", \"stalker\", \"victim\",\n",
    "                     \"immigrants\", \"violence\", \"boy\", \"journalism\", \"rights\",\n",
    "                     \"masculine\", \"femicide\", \"ideology\", \"politics\", \"foreigners\", \"giulia\"]\n",
    "\n",
    "    offsety = 0\n",
    "    \n",
    "    for i in range(len(parole_chiave)):\n",
    "        indiceextra = np.where(etichette==parole_chiave[i])\n",
    "        indiceextra = indiceextra[0][0]\n",
    "        if parole_chiave[i]==\"violenza\":\n",
    "            offsety = 0.4\n",
    "        elif parole_chiave[i]==\"maschile\":\n",
    "            offsety = 0.2\n",
    "        elif parole_chiave[i]==\"immigrati\":\n",
    "            offsety = 0.2\n",
    "        plt.annotate(parole_chiave_sub[i], # etichette[indiceextra]\n",
    "                     (x_vals[indiceextra], y_vals[indiceextra]+offsety),\n",
    "                     color=\"black\", fontsize=25, fontweight='bold'\n",
    "                    )\n",
    "        offsety = 0\n",
    "\n",
    "    plt.axhline(0, color='black', linewidth=1) # origine x, colore, spessore\n",
    "    plt.axvline(0, color='black', linewidth=1) # origine y, colore, spessore\n",
    "    plt.tick_params(axis='both', which='major', labelsize=20) \n",
    "    \n",
    "    plt.savefig(\"Grafico.png\", dpi=3840)\n",
    "\n",
    "disegna_modello(x_vals, y_vals, etichette)\n",
    "\n",
    "Asse_X = pandas.DataFrame(sorted(AVx))\n",
    "Asse_X.to_excel(\"AsseX.xlsx\")\n",
    "Asse_Y = pandas.DataFrame(sorted(AVy))\n",
    "Asse_Y.to_excel(\"AsseY.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99605c-30c3-4286-8fe5-d3153850806c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
